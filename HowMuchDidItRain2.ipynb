{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HowMuchDidItRain2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmminusrslash/notebooks/blob/master/HowMuchDidItRain2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLk409lHAS0Q",
        "colab_type": "text"
      },
      "source": [
        "# How much did it rain II: A timeseries prediction problem\n",
        "https://www.kaggle.com/c/how-much-did-it-rain-ii/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlNDn9g7CiU4",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "Preprocessing logic is the same as from the winning solution https://github.com/simaaron/kaggle-Rain/blob/master/data_preprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtfBtppRG0bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_preprocessed=True # Set to false to read and preprocess data from scratch\n",
        "n_rows=None\n",
        "dataset_name=\"preprocessed\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywLrZTQ1ZwBA",
        "colab_type": "code",
        "outputId": "02189a79-221c-477d-8171-9d5147360b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# upload data to google drive, folder data, then sign in via executing this cell\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPU96NY_AO9t",
        "colab_type": "code",
        "outputId": "2efa36cd-9de5-4ab7-b93f-6464e1cbad84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# confirm that the data can be read\n",
        "! ls \"/content/drive/My Drive/data/\"\n",
        "! mkdir \"/content/drive/My Drive/data/preprocessed\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " kaggle.json\t       sample_dask.py\t\t test.csv\n",
            " preprocessed\t       sample_solution.csv\t train.csv\n",
            "'preprocessed (1)'     sample_solution.csv.zip\t train_head.csv\n",
            "'sample_dask (1).py'   submission_0.csv\n",
            "mkdir: cannot create directory ‘/content/drive/My Drive/data/preprocessed’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZHs_fOdAwfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "feature_cols = ['radardist_km', 'Ref', 'Ref_5x5_10th',\n",
        "                'Ref_5x5_50th', 'Ref_5x5_90th', 'RefComposite', 'RefComposite_5x5_10th',\n",
        "                'RefComposite_5x5_50th', 'RefComposite_5x5_90th', 'RhoHV',\n",
        "                'RhoHV_5x5_10th', 'RhoHV_5x5_50th', 'RhoHV_5x5_90th', 'Zdr',\n",
        "                'Zdr_5x5_10th', 'Zdr_5x5_50th', 'Zdr_5x5_90th', 'Kdp', 'Kdp_5x5_10th',\n",
        "                'Kdp_5x5_50th', 'Kdp_5x5_90th']\n",
        "\n",
        "def impute_missing(data, imputer=None):\n",
        "    '''\n",
        "    fills missing values with median, returns median imputer so that it can be used for inference on test and validation\n",
        "    :param data:\n",
        "    :return:\n",
        "    '''\n",
        "    if imputer is None:\n",
        "        imputer = data[feature_cols].median()\n",
        "        print(\"Median\",imputer)\n",
        "\n",
        "    data = data.fillna(imputer)\n",
        "    return data, imputer\n",
        "\n",
        "def prepare(alldata):\n",
        "    # enumerate samples per gauge minute\n",
        "    g = alldata.groupby('Id').cumcount()\n",
        "    num_measurements_per_gauge = np.array(alldata.groupby('Id')[\"Id\"].count().values)\n",
        "\n",
        "    X = alldata.set_index([alldata.Id, g]) \\\n",
        "        .unstack(fill_value=0) \\\n",
        "        .stack()\n",
        "\n",
        "    if \"Expected\" in alldata.columns:\n",
        "      targets = alldata.groupby(\"Id\")[\"Expected\"] \\\n",
        "          .last().to_numpy()\n",
        "      X=X[X.columns[1:-1]]\n",
        "    else:\n",
        "      targets=[]\n",
        "      X=X[X.columns[1:]]\n",
        "\n",
        "    print(\"final format\")  \n",
        "    # Series, one line per id\n",
        "    X = np.array(X.groupby(level=0) \\\n",
        "                 .apply(lambda x: np.array(x.values))\n",
        "                 .values\n",
        "                 .tolist())\n",
        "\n",
        "    assert len(X)==len(num_measurements_per_gauge)\n",
        "    assert (len(targets)==len(X) or len(targets)==0)\n",
        "    return X, targets, num_measurements_per_gauge\n",
        "\n",
        "\n",
        "def dropNa(train_df):\n",
        "  print(len(train_df))\n",
        "  train_ids = train_df[~np.isnan(train_df.Ref)].Id.unique()\n",
        "  #print(len(train_ids))\n",
        "  train_new = train_df[np.in1d(train_df.Id, train_ids)]\n",
        "  print(len(train_new))\n",
        "  del train_df, train_ids\n",
        "  train_new.head()\n",
        "  return train_new\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us-_fbW8ClJ0",
        "colab_type": "code",
        "outputId": "17702104-c3bd-4cd7-8067-b226d97e9e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "if use_preprocessed:\n",
        "  X_train=np.load(open(\"/content/drive/My Drive/data/%s/X_train\" % dataset_name,\"rb\"))\n",
        "  y_train=np.load(open(\"/content/drive/My Drive/data/%s/y_train\"% dataset_name,\"rb\"))\n",
        "  s=np.load(open(\"/content/drive/My Drive/data/%s/s\"% dataset_name,\"rb\"))\n",
        "  assert len(X_train)==len(y_train)==len(s)\n",
        "else:\n",
        "  print(\"read\")\n",
        "  alldata = pd.read_csv(\"/content/drive/My Drive/data/train.csv\",nrows=n_rows)\n",
        "  print(len(alldata))\n",
        "  print(\"drop\")\n",
        "  alldata=dropNa(alldata)\n",
        "  print(\"Thresholding\")\n",
        "  alldata = alldata[alldata['Expected'] < 73]\n",
        "  print(len(alldata))\n",
        "  print(\"Filling\")\n",
        "  alldata = alldata.fillna(0.0)\n",
        "  print(alldata.isna().sum())\n",
        "  X_train, y_train, s = prepare(alldata)\n",
        "  print(len(alldata))\n",
        "  del alldata\n",
        "  print(\"Saving\")\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/X_train\" % dataset_name,\"wb\"), X_train)\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/y_train\" % dataset_name,\"wb\"), y_train)\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/s\" % dataset_name,\"wb\"), s)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26.7 ms, sys: 1.16 s, total: 1.19 s\n",
            "Wall time: 2.51 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y42bdX8gCA7Q",
        "colab_type": "code",
        "outputId": "64df3442-bf24-4dbc-d2b5-8eb78af94397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "if use_preprocessed:\n",
        "  X_test=np.load(open(\"/content/drive/My Drive/data/%s/X_test\" % dataset_name,\"rb\"))\n",
        "  y_test=np.load(open(\"/content/drive/My Drive/data/%s/y_test\"% dataset_name,\"rb\"))\n",
        "  s_test=np.load(open(\"/content/drive/My Drive/data/%s/s_test\"% dataset_name,\"rb\"))\n",
        "  test_ids=np.load(open(\"/content/drive/My Drive/data/%s/test_ids\"% dataset_name,\"rb\"))\n",
        "  assert len(X_test)==len(s_test)==len(test_ids)\n",
        "else:\n",
        "  testdata=pd.read_csv(\"/content/drive/My Drive/data/test.csv\",nrows=n_rows)\n",
        "  test_ids=testdata.Id.unique()\n",
        "  testdata = testdata.fillna(0.0)\n",
        "  X_test, y_test, s_test = prepare(testdata)\n",
        "  del testdata\n",
        "  print(\"Saving\")\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/test_ids\" % dataset_name,\"wb\"), test_ids)\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/X_test\" % dataset_name,\"wb\"), X_test)\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/y_test\" % dataset_name,\"wb\"), y_test)\n",
        "  np.save(open(\"/content/drive/My Drive/data/%s/s_test\" % dataset_name,\"wb\"), s_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.53 ms, sys: 1.11 s, total: 1.11 s\n",
            "Wall time: 2.44 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkpNDQc_upYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_x,temp_y,temp_s=  X_train, y_train, s  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKuwz2keDSIm",
        "colab_type": "code",
        "outputId": "abba79c5-555e-4648-cb84-b7edbc9b989c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# for fun coded myself, in practice one should use existing utilities like sklearn\n",
        "def val_index(train_size, seed=17,validation_percentage=10):\n",
        "    val_idx = random.choices(list(range(0, 101)),k=validation_percentage)\n",
        "    print(val_idx)\n",
        "    return [i for i in range(train_size) if i%100 in val_idx]    \n",
        "\n",
        "val_idx=val_index(len(temp_x))\n",
        "X_val,y_val, s_val=temp_x[val_idx],temp_y[val_idx],temp_s[val_idx]\n",
        "X_train,y_train, s_train=np.delete(temp_x,val_idx,axis=0),np.delete(temp_y,val_idx,axis=0),np.delete(temp_s,val_idx,axis=0)\n",
        "X_train.shape,X_val.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[77, 84, 70, 2, 50, 69, 81, 27, 88, 96]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((643356, 19, 22), (71482, 19, 22))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkvTBnXiC4jv",
        "colab_type": "text"
      },
      "source": [
        "# Model learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OidFrZ0-C-4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvuiH-jWC_c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.rnn import GRUCell\n",
        "\n",
        "def reset_graph():\n",
        "    np.random.seed(21)\n",
        "    random.seed(21)\n",
        "    tf.reset_default_graph()\n",
        "    tf.random.set_random_seed(22)\n",
        "\n",
        "\n",
        "class Model():\n",
        "\n",
        "    def __init__(self,ff):\n",
        "        self.num_layers = 1\n",
        "        self.num_steps = 19\n",
        "        self.num_features = 22\n",
        "        self.learn_rate = 1e-3\n",
        "        self.ff=ff\n",
        "\n",
        "    def build(self):\n",
        "        reset_graph()\n",
        "        self.inputs = tf.placeholder(shape=[None, self.num_steps, self.num_features], dtype=tf.float32)  # batch_size x num_steps x num_features\n",
        "        self.seq_lengths = tf.placeholder(shape=[None], dtype=tf.int32)\n",
        "        self.targets = tf.placeholder(shape=[None], dtype=tf.float32)\n",
        "        self.is_training = tf.placeholder_with_default(True, shape=(), name=\"is_training\")\n",
        "\n",
        "        num_outputs = 1\n",
        "\n",
        "        if self.ff:\n",
        "          self.flattened_inputs=tf.concat(values=self.inputs, axis=0, name=\"flatten\")\n",
        "          print(self.flattened_inputs.shape)\n",
        "          l1=tf.layers.dense(self.flattened_inputs, 512, activation=tf.nn.relu )\n",
        "          l2=tf.layers.dense(l1, 200 ,activation=tf.nn.relu)\n",
        "          self.logits = tf.layers.dense(l2, num_outputs,activation=None)  #final_state[-1].h if lstm cell is used\n",
        "        else:\n",
        "          cells = tf.contrib.rnn.GRUCell(num_units=64, activation=tf.nn.relu, dtype= tf.float32) \n",
        "          self.outputs, self.final_state = tf.nn.dynamic_rnn(cells, self.inputs,\n",
        "                                                      sequence_length=self.seq_lengths,\n",
        "                                                       dtype=tf.float32)  # 'final_state' is a tensor of shape [batch_size, cell_state_size]\n",
        "          self.logits = tf.layers.dense(self.final_state, num_outputs,activation=None)  #final_state[-1].h if lstm cell is used\n",
        "\n",
        "        self.diff=tf.abs(tf.subtract(self.targets,tf.reshape(self.logits,[-1])))\n",
        "        self.loss =  tf.reduce_mean(self.diff) \n",
        "\n",
        "        self.train_op = tf.train.AdamOptimizer(self.learn_rate).minimize(self.loss)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "145y4CwoKztM",
        "colab_type": "code",
        "outputId": "109557d5-f518-44f6-e24d-e8ddf3dea46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "m = Model(ff=False)\n",
        "m.build()\n",
        "\n",
        "num_epochs=500\n",
        "batch_size=1024\n",
        "batch_size_val=np.minimum(2048,len(y_val)//2)\n",
        "with tf.Session() as sess:\n",
        "        tf.random.set_random_seed(18)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        saver = tf.train.Saver()\n",
        "        best_loss=1000\n",
        "        no_improvement=0\n",
        "        for e in range(num_epochs):\n",
        "            print(\"Epoch \",e)\n",
        "            train_loss=[]\n",
        "            ids=list(range(len(X_train)))\n",
        "            np.random.shuffle(ids)\n",
        "            X_train=X_train[ids]\n",
        "            y_train=y_train[ids]\n",
        "            s_train=s_train[ids]\n",
        "            \n",
        "            for i in range(0,int(len(y_train)/batch_size)):\n",
        "            \n",
        "              _, l = sess.run([m.train_op,m.loss], feed_dict={\n",
        "                                                     m.inputs: X_train[i*batch_size:(i+1)*batch_size], \n",
        "                                                     #m.inputs: X_train[:100], \n",
        "                                                     m.targets: y_train[i*batch_size:(i+1)*batch_size], \n",
        "                                                     m.seq_lengths: s_train[i*batch_size:(i+1)*batch_size],\n",
        "                                                   m.is_training: True})\n",
        "              train_loss.append(l)\n",
        "              if i % 100 == 0 and i >0:\n",
        "                  val_losses=[]\n",
        "                  for b in range(0,int(len(y_val)/batch_size_val)):\n",
        "                    loss=sess.run([m.loss],feed_dict={m.inputs: X_val[b*batch_size_val:(b+1)*batch_size_val], \n",
        "                                                      m.targets: y_val[b*batch_size_val:(b+1)*batch_size_val], \n",
        "                                                      m.seq_lengths: s_val[b*batch_size_val:(b+1)*batch_size_val],\n",
        "                                                      m.is_training: False})\n",
        "                    val_losses.append(loss)\n",
        "                  val_loss=np.average(val_losses)\n",
        "                  print(\"Instance %s, train loss %.3f, val loss %.3f, best val loss %.3f\"% ((i+1)*batch_size,np.average(train_loss[-100:]),val_loss,best_loss))\n",
        "\n",
        "                  if val_loss<best_loss:\n",
        "                    save_path = saver.save(sess, \"/tmp/model.ckpt\")\n",
        "                    best_loss=val_loss\n",
        "                    no_improvement=0\n",
        "                  else:\n",
        "                    no_improvement+=1\n",
        "                  \n",
        "                  if no_improvement>5:\n",
        "                      break\n",
        "            if no_improvement>5:\n",
        "                      break\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0\n",
            "Instance 103424, train loss 2.880, val loss 2.607, best val loss 1000.000\n",
            "Instance 205824, train loss 2.585, val loss 2.517, best val loss 2.607\n",
            "Instance 308224, train loss 2.490, val loss 2.465, best val loss 2.517\n",
            "Instance 410624, train loss 2.449, val loss 2.469, best val loss 2.465\n",
            "Instance 513024, train loss 2.458, val loss 2.431, best val loss 2.465\n",
            "Instance 615424, train loss 2.455, val loss 2.455, best val loss 2.431\n",
            "Epoch  1\n",
            "Instance 103424, train loss 2.432, val loss 2.417, best val loss 2.431\n",
            "Instance 205824, train loss 2.428, val loss 2.412, best val loss 2.417\n",
            "Instance 308224, train loss 2.415, val loss 2.407, best val loss 2.412\n",
            "Instance 410624, train loss 2.426, val loss 2.396, best val loss 2.407\n",
            "Instance 513024, train loss 2.403, val loss 2.404, best val loss 2.396\n",
            "Instance 615424, train loss 2.393, val loss 2.394, best val loss 2.396\n",
            "Epoch  2\n",
            "Instance 103424, train loss 2.371, val loss 2.389, best val loss 2.394\n",
            "Instance 205824, train loss 2.398, val loss 2.403, best val loss 2.389\n",
            "Instance 308224, train loss 2.398, val loss 2.385, best val loss 2.389\n",
            "Instance 410624, train loss 2.409, val loss 2.403, best val loss 2.385\n",
            "Instance 513024, train loss 2.401, val loss 2.391, best val loss 2.385\n",
            "Instance 615424, train loss 2.406, val loss 2.383, best val loss 2.385\n",
            "Epoch  3\n",
            "Instance 103424, train loss 2.392, val loss 2.390, best val loss 2.383\n",
            "Instance 205824, train loss 2.393, val loss 2.378, best val loss 2.383\n",
            "Instance 308224, train loss 2.405, val loss 2.371, best val loss 2.378\n",
            "Instance 410624, train loss 2.378, val loss 2.377, best val loss 2.371\n",
            "Instance 513024, train loss 2.396, val loss 2.376, best val loss 2.371\n",
            "Instance 615424, train loss 2.369, val loss 2.388, best val loss 2.371\n",
            "Epoch  4\n",
            "Instance 103424, train loss 2.367, val loss 2.384, best val loss 2.371\n",
            "Instance 205824, train loss 2.385, val loss 2.376, best val loss 2.371\n",
            "Instance 308224, train loss 2.372, val loss 2.372, best val loss 2.371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB2HIl1XulFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8cd082f-d957-44c8-d92d-19bd420d5ca1"
      },
      "source": [
        "#save submission\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.Saver()\n",
        "    saver.restore(sess,\"/tmp/model.ckpt\")\n",
        "    predictions=[]\n",
        "    for b in range(0,int(len(X_test)/batch_size_val)+1):\n",
        "      pred=sess.run(m.logits,feed_dict={m.inputs: X_test[b*batch_size_val:(b+1)*batch_size_val], \n",
        "                                                m.seq_lengths: s_test[b*batch_size_val:(b+1)*batch_size_val],\n",
        "                                                m.is_training: False})\n",
        "      predictions.extend(pred.reshape(-1))\n",
        "      print(len(predictions),len(test_ids))\n",
        "    \n",
        "    submission_0 = pd.DataFrame({'Id': test_ids, 'Expected': predictions})\n",
        "    submission_0.to_csv('/content/drive/My Drive/data/submission_0.csv', index=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/model.ckpt\n",
            "2048 717625\n",
            "4096 717625\n",
            "6144 717625\n",
            "8192 717625\n",
            "10240 717625\n",
            "12288 717625\n",
            "14336 717625\n",
            "16384 717625\n",
            "18432 717625\n",
            "20480 717625\n",
            "22528 717625\n",
            "24576 717625\n",
            "26624 717625\n",
            "28672 717625\n",
            "30720 717625\n",
            "32768 717625\n",
            "34816 717625\n",
            "36864 717625\n",
            "38912 717625\n",
            "40960 717625\n",
            "43008 717625\n",
            "45056 717625\n",
            "47104 717625\n",
            "49152 717625\n",
            "51200 717625\n",
            "53248 717625\n",
            "55296 717625\n",
            "57344 717625\n",
            "59392 717625\n",
            "61440 717625\n",
            "63488 717625\n",
            "65536 717625\n",
            "67584 717625\n",
            "69632 717625\n",
            "71680 717625\n",
            "73728 717625\n",
            "75776 717625\n",
            "77824 717625\n",
            "79872 717625\n",
            "81920 717625\n",
            "83968 717625\n",
            "86016 717625\n",
            "88064 717625\n",
            "90112 717625\n",
            "92160 717625\n",
            "94208 717625\n",
            "96256 717625\n",
            "98304 717625\n",
            "100352 717625\n",
            "102400 717625\n",
            "104448 717625\n",
            "106496 717625\n",
            "108544 717625\n",
            "110592 717625\n",
            "112640 717625\n",
            "114688 717625\n",
            "116736 717625\n",
            "118784 717625\n",
            "120832 717625\n",
            "122880 717625\n",
            "124928 717625\n",
            "126976 717625\n",
            "129024 717625\n",
            "131072 717625\n",
            "133120 717625\n",
            "135168 717625\n",
            "137216 717625\n",
            "139264 717625\n",
            "141312 717625\n",
            "143360 717625\n",
            "145408 717625\n",
            "147456 717625\n",
            "149504 717625\n",
            "151552 717625\n",
            "153600 717625\n",
            "155648 717625\n",
            "157696 717625\n",
            "159744 717625\n",
            "161792 717625\n",
            "163840 717625\n",
            "165888 717625\n",
            "167936 717625\n",
            "169984 717625\n",
            "172032 717625\n",
            "174080 717625\n",
            "176128 717625\n",
            "178176 717625\n",
            "180224 717625\n",
            "182272 717625\n",
            "184320 717625\n",
            "186368 717625\n",
            "188416 717625\n",
            "190464 717625\n",
            "192512 717625\n",
            "194560 717625\n",
            "196608 717625\n",
            "198656 717625\n",
            "200704 717625\n",
            "202752 717625\n",
            "204800 717625\n",
            "206848 717625\n",
            "208896 717625\n",
            "210944 717625\n",
            "212992 717625\n",
            "215040 717625\n",
            "217088 717625\n",
            "219136 717625\n",
            "221184 717625\n",
            "223232 717625\n",
            "225280 717625\n",
            "227328 717625\n",
            "229376 717625\n",
            "231424 717625\n",
            "233472 717625\n",
            "235520 717625\n",
            "237568 717625\n",
            "239616 717625\n",
            "241664 717625\n",
            "243712 717625\n",
            "245760 717625\n",
            "247808 717625\n",
            "249856 717625\n",
            "251904 717625\n",
            "253952 717625\n",
            "256000 717625\n",
            "258048 717625\n",
            "260096 717625\n",
            "262144 717625\n",
            "264192 717625\n",
            "266240 717625\n",
            "268288 717625\n",
            "270336 717625\n",
            "272384 717625\n",
            "274432 717625\n",
            "276480 717625\n",
            "278528 717625\n",
            "280576 717625\n",
            "282624 717625\n",
            "284672 717625\n",
            "286720 717625\n",
            "288768 717625\n",
            "290816 717625\n",
            "292864 717625\n",
            "294912 717625\n",
            "296960 717625\n",
            "299008 717625\n",
            "301056 717625\n",
            "303104 717625\n",
            "305152 717625\n",
            "307200 717625\n",
            "309248 717625\n",
            "311296 717625\n",
            "313344 717625\n",
            "315392 717625\n",
            "317440 717625\n",
            "319488 717625\n",
            "321536 717625\n",
            "323584 717625\n",
            "325632 717625\n",
            "327680 717625\n",
            "329728 717625\n",
            "331776 717625\n",
            "333824 717625\n",
            "335872 717625\n",
            "337920 717625\n",
            "339968 717625\n",
            "342016 717625\n",
            "344064 717625\n",
            "346112 717625\n",
            "348160 717625\n",
            "350208 717625\n",
            "352256 717625\n",
            "354304 717625\n",
            "356352 717625\n",
            "358400 717625\n",
            "360448 717625\n",
            "362496 717625\n",
            "364544 717625\n",
            "366592 717625\n",
            "368640 717625\n",
            "370688 717625\n",
            "372736 717625\n",
            "374784 717625\n",
            "376832 717625\n",
            "378880 717625\n",
            "380928 717625\n",
            "382976 717625\n",
            "385024 717625\n",
            "387072 717625\n",
            "389120 717625\n",
            "391168 717625\n",
            "393216 717625\n",
            "395264 717625\n",
            "397312 717625\n",
            "399360 717625\n",
            "401408 717625\n",
            "403456 717625\n",
            "405504 717625\n",
            "407552 717625\n",
            "409600 717625\n",
            "411648 717625\n",
            "413696 717625\n",
            "415744 717625\n",
            "417792 717625\n",
            "419840 717625\n",
            "421888 717625\n",
            "423936 717625\n",
            "425984 717625\n",
            "428032 717625\n",
            "430080 717625\n",
            "432128 717625\n",
            "434176 717625\n",
            "436224 717625\n",
            "438272 717625\n",
            "440320 717625\n",
            "442368 717625\n",
            "444416 717625\n",
            "446464 717625\n",
            "448512 717625\n",
            "450560 717625\n",
            "452608 717625\n",
            "454656 717625\n",
            "456704 717625\n",
            "458752 717625\n",
            "460800 717625\n",
            "462848 717625\n",
            "464896 717625\n",
            "466944 717625\n",
            "468992 717625\n",
            "471040 717625\n",
            "473088 717625\n",
            "475136 717625\n",
            "477184 717625\n",
            "479232 717625\n",
            "481280 717625\n",
            "483328 717625\n",
            "485376 717625\n",
            "487424 717625\n",
            "489472 717625\n",
            "491520 717625\n",
            "493568 717625\n",
            "495616 717625\n",
            "497664 717625\n",
            "499712 717625\n",
            "501760 717625\n",
            "503808 717625\n",
            "505856 717625\n",
            "507904 717625\n",
            "509952 717625\n",
            "512000 717625\n",
            "514048 717625\n",
            "516096 717625\n",
            "518144 717625\n",
            "520192 717625\n",
            "522240 717625\n",
            "524288 717625\n",
            "526336 717625\n",
            "528384 717625\n",
            "530432 717625\n",
            "532480 717625\n",
            "534528 717625\n",
            "536576 717625\n",
            "538624 717625\n",
            "540672 717625\n",
            "542720 717625\n",
            "544768 717625\n",
            "546816 717625\n",
            "548864 717625\n",
            "550912 717625\n",
            "552960 717625\n",
            "555008 717625\n",
            "557056 717625\n",
            "559104 717625\n",
            "561152 717625\n",
            "563200 717625\n",
            "565248 717625\n",
            "567296 717625\n",
            "569344 717625\n",
            "571392 717625\n",
            "573440 717625\n",
            "575488 717625\n",
            "577536 717625\n",
            "579584 717625\n",
            "581632 717625\n",
            "583680 717625\n",
            "585728 717625\n",
            "587776 717625\n",
            "589824 717625\n",
            "591872 717625\n",
            "593920 717625\n",
            "595968 717625\n",
            "598016 717625\n",
            "600064 717625\n",
            "602112 717625\n",
            "604160 717625\n",
            "606208 717625\n",
            "608256 717625\n",
            "610304 717625\n",
            "612352 717625\n",
            "614400 717625\n",
            "616448 717625\n",
            "618496 717625\n",
            "620544 717625\n",
            "622592 717625\n",
            "624640 717625\n",
            "626688 717625\n",
            "628736 717625\n",
            "630784 717625\n",
            "632832 717625\n",
            "634880 717625\n",
            "636928 717625\n",
            "638976 717625\n",
            "641024 717625\n",
            "643072 717625\n",
            "645120 717625\n",
            "647168 717625\n",
            "649216 717625\n",
            "651264 717625\n",
            "653312 717625\n",
            "655360 717625\n",
            "657408 717625\n",
            "659456 717625\n",
            "661504 717625\n",
            "663552 717625\n",
            "665600 717625\n",
            "667648 717625\n",
            "669696 717625\n",
            "671744 717625\n",
            "673792 717625\n",
            "675840 717625\n",
            "677888 717625\n",
            "679936 717625\n",
            "681984 717625\n",
            "684032 717625\n",
            "686080 717625\n",
            "688128 717625\n",
            "690176 717625\n",
            "692224 717625\n",
            "694272 717625\n",
            "696320 717625\n",
            "698368 717625\n",
            "700416 717625\n",
            "702464 717625\n",
            "704512 717625\n",
            "706560 717625\n",
            "708608 717625\n",
            "710656 717625\n",
            "712704 717625\n",
            "714752 717625\n",
            "716800 717625\n",
            "717625 717625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKm34_rluovT",
        "colab_type": "text"
      },
      "source": [
        "# Simple Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l826T6Sb3d6Z",
        "colab_type": "code",
        "outputId": "793848b1-aac5-4bc8-dc8c-8c2841ff54a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from keras.layers import Input, Dense, GRU,CuDNNLSTM\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "N_EPOCHS = 50\n",
        "\n",
        "def get_model_simple(shape=(19,22)):\n",
        "    inp = Input(shape)\n",
        "    x =  GRU(64, return_sequences=False,activation=tf.nn.relu)(inp)\n",
        "    x = Dense(1)(x)\n",
        "    model = Model(inp, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "model_0 = get_model_simple((None,22))\n",
        "model_0.compile(optimizer='adam', loss='mae')\n",
        "model_0.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, 22)          0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                16704     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 16,769\n",
            "Trainable params: 16,769\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px4XuWB6Rij8",
        "colab_type": "code",
        "outputId": "32dc6321-bfca-4c3c-c639-697f48fa069e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "es_callback = EarlyStopping(monitor='val_loss', min_delta=0, patience=5)\n",
        "\n",
        "model_0.fit(X_train, y_train, \n",
        "            batch_size=BATCH_SIZE, epochs=N_EPOCHS, \n",
        "            validation_data=(X_val,y_val), callbacks=[es_callback])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 643356 samples, validate on 71482 samples\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "643356/643356 [==============================] - 14s 21us/step - loss: 2.4769 - val_loss: 2.4395\n",
            "Epoch 2/50\n",
            "643356/643356 [==============================] - 13s 20us/step - loss: 2.4059 - val_loss: 2.4260\n",
            "Epoch 3/50\n",
            "643356/643356 [==============================] - 13s 20us/step - loss: 2.3866 - val_loss: 2.4122\n",
            "Epoch 4/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3775 - val_loss: 2.4072\n",
            "Epoch 5/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3738 - val_loss: 2.4521\n",
            "Epoch 6/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3660 - val_loss: 2.4135\n",
            "Epoch 7/50\n",
            "643356/643356 [==============================] - 13s 20us/step - loss: 2.3579 - val_loss: 2.4098\n",
            "Epoch 8/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3560 - val_loss: 2.3859\n",
            "Epoch 9/50\n",
            "643356/643356 [==============================] - 13s 20us/step - loss: 2.3527 - val_loss: 2.3849\n",
            "Epoch 10/50\n",
            "643356/643356 [==============================] - 13s 19us/step - loss: 2.3486 - val_loss: 2.4198\n",
            "Epoch 11/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3463 - val_loss: 2.3947\n",
            "Epoch 12/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3455 - val_loss: 2.3861\n",
            "Epoch 13/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3415 - val_loss: 2.3944\n",
            "Epoch 14/50\n",
            "643356/643356 [==============================] - 12s 19us/step - loss: 2.3403 - val_loss: 2.3948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6b28d25f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KABuZAX2WBS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_0 = model_0.predict(X_test)\n",
        "submission_0 = pd.DataFrame({'Id': test_ids, 'Expected': y_pred_0.reshape(-1)})\n",
        "submission_0.to_csv('/content/drive/My Drive/data/submission_keras.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugtdzkurCIc6",
        "colab_type": "code",
        "outputId": "e62df653-ee2a-4003-8bf2-c9a54664ec60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(list(zip(y_val[:10],pred[:10].reshape(-1))))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0.50800025, 0.6755886), (0.7620004, 0.8104479), (4.0640019999999994, 1.8330603), (1.2700007, 3.3346477), (0.50800025, 0.25874883), (1.5240008, 0.5065918), (2.0320009999999997, 0.33316383), (1.0160004999999999, 0.68877053), (0.50800025, 1.2990577), (0.25400013, 1.0149037)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkJdfqGkxv4E",
        "colab_type": "text"
      },
      "source": [
        "# Submission\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWKRtBWMLFfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install kaggle --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWYF79fiLkn8",
        "colab_type": "code",
        "outputId": "c5cdac04-18e5-4e30-f876-4ef27526f32c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "! export KAGGLE_CONFIG_DIR='/content/drive/My Drive/data/'; kaggle competitions submit -c how-much-did-it-rain-ii -f '/content/drive/My Drive/data/submission_keras.csv' -m \"keras,simple Gru\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 17.6M/17.6M [00:00<00:00, 25.7MB/s]\n",
            "Successfully submitted to How Much Did It Rain? II"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7lZYguacAcZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f538c827-201f-44c6-e0ed-47e145c7fe64"
      },
      "source": [
        "! export KAGGLE_CONFIG_DIR='/content/drive/My Drive/data/'; kaggle competitions submit -c how-much-did-it-rain-ii -f '/content/drive/My Drive/data/submission_0.csv' -m \"olf plain tf,simple Gru\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 17.7M/17.7M [00:06<00:00, 2.69MB/s]\n",
            "Successfully submitted to How Much Did It Rain? II"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGBLu7BCXSyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}